<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Mémoire</title>
  <link rel="stylesheet" href="style.css">
</head>

<body>
  <section id="intro" class="chapter" data-chapter="0">
    <h1>Introduction</h1>
    <p>S’il y a bien un terme que l’industrie numérique revendique systématiquement, c’est celui-ci : simplicité.
    </p>
    <p>
      Alors qu’en 2007 Steve Jobs annonçait l’iPhone, un mot était récurent tout au long de sa présentation : simple. Ce
      terme
      deviendra le leitmotiv de la présentation de tout produit technologique pour grand public. <em>Simple.</em>
      Débarrassés
      des boutons grossiers qui occupaient les téléphones de l’époque, l’écran et ce qu’il montrait occupaient désormais
      une place capitale. La simplicité dont Steve Jobs chantait les louanges ne se manifestait pas seulement dans
      l’objet physique. La véritable simplicité semblait résider au-delà de la vitre, dans la manière dont on utilisait
      cet ordinateur miniature. Alors que l’écran recouvrait la totalité du téléphone, l’interface graphique prenait le
      dessus.
    </p>
    <p>

      L’interface graphique, communément désignée par l’acronyme GUI <span class="margin-note">Graphical user
        interface</span> est la frontière entre
      l’utilisateur et l’ordinateur, entre le code, et le logiciel (ou l’application) qu’il manipule. Elle se positionne
      comme médiatrice, transformant ces instructions cryptiques en formes standardisées, intelligibles par l’humain. Si
      Anthony Masure nous propose la définition suivante :
      « Une interface est un empilement de couches techniques dont les effets masquent le fonctionnement interne des
      machines »
      nous pouvons avancer que l’interface graphique est la strate supérieure de cet empilement de couches.
    </p>
    <p>

      Cette formulation semble impliquer que l’interface graphique devrait occulter la réalité technique des processus
      aux œuvres dans nos ordinateurs. Mais est-ce vraiment la condition sine qua non de l’existence d’une interface
      graphique ?
    </p>
    <p>

      Si l’iPhone est si important dans l’histoire de l’interface graphique, c’est parce qu’il a donné naissance à une
      nouvelle ère. Une ère où l’affordance des interfaces virtuelles est la préoccupation principale des designers
      d’interface. Il a ouvert le chemin à la prolifération d’interfaces graphiques accessibles, manipulables par le
      grand public, et ce, au prix d’une certaine perte de liberté de l’utilisateur. Cette motivation de rechercher la
      facilité d’utilisation comme finalité n’a pourtant pas été la raison de la naissance des interfaces graphiques.
    </p>
    <p>

      À la fois formidable solution pour manipuler un ordinateur avec peu de connaissances au préalable ou effectuer du
      travail graphique, l’interface graphique est aussi ce qui vient dissimuler le fonctionnement de la machine et
      limiter la connaissance de l’utilisateur, l’empêchant de s’émanciper pleinement par la technologie. Elle serait
      donc un pharmakon. En reprenant ce terme largement employé par Bernard Stiegler afin de qualifier les objets
      techniques, je cherche à souligner l’ambiguïté du rôle du GUI.
    </p>
    <p>

      Sous le fantasme d’un monde où la puissance des ordinateurs est accessible à un public plus vaste que des
      ingénieurs, les interfaces graphiques ont une puissance de contrôle qui n’est pas systématiquement perceptible. À
      l’heure où notre société tend à tout numériser (travail, loisir, communication, consommation), il est
      problématique d’imaginer la majeure partie du monde comme ayant une compréhension de la technologie qu’ils
      utilisent quotidiennement qui s’arrête à l’image que leur renvoient leurs écrans. Il convient alors de se poser la
      question suivante : peut-on accepter que la simplicité d’utilisation d’un ordinateur soit une fin en soi ?
    </p>
    <p>

      Nous chercherons à comprendre comment la recherche de la simplicité s’est imposée comme axiome au cours de
      l’histoire du design d’interface. Dans un second temps, nous émettrons une critique de cette philosophie.
    </p>
    </p>
  </section>


  <section id="first" class="chapter" data-chapter="1">
    <h1>Origines de l’interface</h1>

    <p>Augmentation Research Center, Stanford Research Institute, année 68. Douglas Engelbart et son équipe présentent
      une machine qui donnera forme à l’informatique pour les décennies à venir. Au cours de cet évènement dont on se
      rappellera plus tard sous le nom de « the mother of all demo » le oN-Line System, ou NLS est révélé. C’est le
      premier ordinateur employant une utilisation pratique de liens hypertextes, de la souris, de l’e-mail et bien
      d’autres principes modernes de l’informatique. L’utilisation d’un nouveau type d’écran à matrice de points permis
      même la représentation d’image vidéo, et leur diffusion en temps réel. Il fut surtout le premier ordinateur à être
      doté d’une interface graphique permettant la représentation et l’édition de documents en deux dimensions. Nous
      sommes bien loin des ordinateurs de cette époque, les super calculateurs, machines gigantesques avec lesquelles on
      communique généralement avec des cartes perforées, des kilomètres de câbles ou des étendues d’interrupteurs.
    </p>

    <p>

      Cette manière radicalement nouvelle d’interagir avec les ordinateurs ne résulte pas de la volonté de simplifier
      leur usage. En 1960, J.C.R. Licklider revendiquait la nécessité de développer une informatique sensible à des
      changements de variables, une informatique en temps réel dans un essai intitulé « Man Computer Symbiosis ». Cet
      écrit influença Engelbart : deux ans plus tard, il écrivait « Augmenting Human Intellect », un essai soutenant que
      l’ordinateur avait le potentiel d’assister l’humain dans des tâches autres que le calcul mathématique.
    </p>


    <p class="cite">

      « Dans une telle relation future de travail entre l’appareil à résoudre les problèmes humains et l’ordinateur
      agissant comme un valet, l’aptitude de l’ordinateur à exécuter des processus mathématiques serait utilisée pour
      être appliquée à une autre tâche au moment où on en aurait besoin. L’ordinateur présente bien d’autres aptitudes
      de manipulation et d’affichage de l’information, susceptibles de représenter un bénéfice significatif pour
      l’être
      humain dans des processus non mathématiques de planification, d’organisation, d’étude, etc. Toute personne qui
      organise sa pensée en utilisant des concepts symbolisés (que ce soit sous la forme de la langue anglaise, de
      pictogrammes, de logique formelle, ou de mathématiques) devrait être en mesure d’en bénéficier de manière
      significative. »
    </p>
    <p class="description">Douglas Engelbart - <em>Augmenting human intellect</em></p>

    <div class="img-in-text">
      <img src="./img/NLSinterface.jpg" id="img_01" />
      <p class="description"><em>Vidéo-conférence sur le NLS, 1968.</em></p>
    </div>

    <p class="after-cite">

      Douglas Engelbart voyait un potentiel dans les ordinateurs autre que celui de broyer des nombres. L’un des
      premiers usages qu’il suggère est celui d’un architecte concevant un bâtiment dans quelque chose de similaire à un
      logiciel de CAD. Mais il est impensable de réaliser une telle tâche sur un superordinateur. Là où les ordinateurs
      de l’époque demandaient de préparer des bandes perforées, les nourrir à la machine et obtenir un résultat après
      calcul, l’application que souhaite Engelbart nécessite de créer des interfaces physiques permettant un retour
      immédiat de la machine. Le NLS possédera donc un clavier permettant de lui adresser directement des commandes. Il
      conçoit aussi quantité de prototypes pour arriver à son « Indicateur de position X-Y destiné à un système d’écran
      d’affichage ». Objet qui adoptera rapidement le surnom plus concis de « souris ». Malgré cette innovation
      fluidifiant le rapport entre humain et machine, l’ordinateur demande un temps d’apprentissage conséquent.
    </p>

    <p>

      Non satisfaits de la direction que prend le laboratoire de recherche dans les années qui suivent la démo de NLS,
      de nombreux chercheurs du SRI décident de rejoindre le Xerox Palo Alto Research Center, en emmenant avec eux
      l’idée de la souris. Au sein de PARC, des chercheurs tels que Alan Kay et Adele Goldberg travaillèrent sur le
      Xerox Alto, présenté en 1973. Il introduit le Smalltalk, à la fois environnement de développement graphique (tels
      les Environnements de Développements Intégrés que nous connaissons aujourd’hui) et gestionnaire de fenêtre.
      Smalltalk eut une grande influence sur la forme que prirent les langages de programmation orienté objet par la
      suite. Quand Kay et son équipe décident de le créer, ils souhaitent rendre le langage informatique naturel, de
      manière à ce que des néophytes puissent se l’approprier aisément.3 Dans un souci d’accessibilité, le Smalltalk
      introduit la métaphore du bureau.
    </p>

    <p>

      Le GUI de l’Alto pouvait alors posséder plusieurs applications ouvertes en même temps, dans différentes fenêtres.
      De plus cet ordinateur possède la première interface WYSIWYG (What You See Is What You Get) : cet acronyme désigne
      une nouvelle manière de travailler avec un ordinateur : le document sur lequel on travaille numériquement aura la
      même apparence dans le logiciel, qu’une fois imprimé. Cette logique rompt avec la traditionnelle compilation du
      code. Il n’est plus nécessaire de modifier un fichier et de le recompiler entièrement afin d’apprécier ses
      changements.
    </p>
    <p>

      Désormais, chaque entrée apparaît à l’utilisateur formatée, sous l’apparence que pourrait avoir le résultat final.
      Ce changement de paradigme permet aux utilisateurs de l’Alto d’itérer sur leur travail plus rapidement.
      L’utilisateur et l’ordinateur s’affectent mutuellement et réciproquement.
    </p>

    <p>

      La machine, dotée d’un écran vertical est pensée comme un outil de mise en page. Les ordinateurs de cette époque
      n’étant pas encore communément envisagés comme des supports de diffusion de médias ou de communication, la
      finalité de tout travail de mise en page se devait d’être imprimée.
    </p>

    <p>

      Les avancées que l’Alto aura introduites ne deviendront accessibles au public qu’en 1981. Là où l’Alto était un
      projet expérimental, le Xerox 8010 Information System, ou Xerox Star est un ordinateur commercial, destiné à être
      adopté par des bureaux. La métaphore du bureau introduit avec le Smalltalk se concrétise : il n’est plus
      nécessaire pour l’utilisateur d’être un spécialiste pour utiliser un ordinateur. Cependant, au vu du prix de
      l’installation d’un parc informatique (50 000 à 100 000 $ pour 2-3 ordinateurs, et serveurs), le Xerox Parc n’est
      vendu qu’à 25 000 exemplaires, c’est un échec commercial. Si nous connaissons assez peu les ordinateurs de Xerox
      Parc aujourd’hui, ce centre de recherche aura indirectement donné naissance au Lisa et au Macintosh, à la suite de
      la visite de Steve Jobs et d’ingénieurs d’Apple en 1979.
    </p>

    <p>

      Ces quelques exemples nous donnent une base pour comprendre l’origine de l’interface graphique. La volonté
      d’employer les ordinateurs pour de nouveaux usages devait passer nécessairement par la création d’une interface
      permettant l’entrée de données et un retour visuel en temps réel. Les périphériques de l’époque dédiés à cette
      tâche étant peu appropriés, de nouveaux furent créés, essentiellement par des ingénieurs. L’apparence que prirent
      ces outils de visualisations de données fut directement héritée d’un média préexistant : la page5. Sans doute, cet
      héritage de la page est lié à la nature du travail à effectuer avec ces premiers ordinateurs : l’édition de
      documents. Les créateurs de ces interfaces revendiquèrent d’ailleurs leurs conceptions comme des simulations
      d’outils préexistants6, une reproduction virtuelle d’objets physiques auxquels on aurait ajouté de nouvelles
      propriétés. Les progrès informatiques de l’époque étaient motivés par la perspective d’employer les ordinateurs à
      des tâches nouvelles et d’émanciper technologiquement leurs utilisateurs : augmenter l’intellect humain.
    </p>
    
    <p class="description">Page suivante : <em>Xerox Alto, 1973.</em></p>

    <div class="img-full-page">
      <img src="./img/alto_4x.jpg" class="img-full-page-child" id="img_02" />
    </div>

  </section>

  <section id="second" class="chapter" data-chapter="2">
    <h1>La simplicité se vend bien</h1>

    <p>Si aujourd’hui un terme résonne dans tous les discours des entrepreneurs de la Silicon Valley, c’est bien
      celui-ci : simplicité. À en voir les publicités vantant la facilité d’utilisation d’un téléphone ou d’une
      application, il semblerait que la moindre friction n’a pas sa place dans l’utilisation d’un logiciel. Dès lors que
      l’utilisateur viendrait s’interroger sur la manière d’utiliser le logiciel, l’interface n’aurait pas rempli son
      rôle. Tous les concepteurs semblent partager le même fantasme : celui d’une interface parfaitement instinctive, où
      le moindre doute serait inexistant.</p>
  </section>
  <script src="https://unpkg.com/pagedjs/dist/paged.polyfill.js"></script>
  <script src="marginNotes.js"></script>
</body>

</html>